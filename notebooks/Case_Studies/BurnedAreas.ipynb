{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitoring burnt areas in Wales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fire has been part of the natural ecology of upland and some lowland\n",
    "environments, particularly heathlands, for many thousands of years.\n",
    "These occur naturally as a result of lightning strikes and fire is also one of the\n",
    "oldest land-management tools used for agriculture and game management\n",
    "and has more recently been used to assist wildlife conservation management.\n",
    "A range of semi-natural habitats are subject to managed (prescribed) burning including\n",
    "moorlands and heathlands but also some mires and other wetlands\n",
    "(e.g., reedbeds), grasslands and scrub. Carefully planned, periodic and\n",
    "controlled burning can be beneficial for land management and the wider environment.\n",
    "However, in some circumstances, burning (particularly if illegal) may also be unsafe and damaging and is being exaccerbated also by climate change (e.g., higher temperatures and prolonged periods of drought)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image of Yaktocat](https://ichef.bbci.co.uk/news/976/cpsprodpb/6EEF/production/_123899382_mediaitem123899380.jpg.webp)\n",
    "         \n",
    "                                   Burning in Mynydd Mawr. Photograph:BBC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "This notebook demonstrates how the new Wales Data Cube allows rapid analysis of multiple years of Sentinel-2 optical data, which allows monitoring of burnt areas. \n",
    "\n",
    "Contrary to radar data, which are strongly correlated to height and texture, optical sensors are mainly sensitive to colour and chemistry (e.g., plant water, chlorophyll content) and, as a consequence, are very useful for monitoring vegetation health. However, the disadvantage of optical data is that land surface is often obscured by cloud and smoke haze, which impedes observations.\n",
    "\n",
    "The Living Wales project has allowed the generation of national annual land cover maps, which are being translated to annual habitat maps with mapped classes aligning with the Phase 1 Habitat Taxonomy.   Living Wales is also actively involved in the development of a new digital infrastructure (incl. Open Data Cube technology) for Wales, that routinely provides both Sentinel-1 radar and Sentinel-2 optical data in an Analysis Ready Data (ARD) format. These have been processed according to a minimum set of requirements and organized into a form that allows immediate analysis with minimum additional user effort and generation of derived products.  \n",
    "\n",
    "This notebook uses the Sentinel-2 ARD as well as a python library for mapping burnt areas and identifying and estimating the area of impacted habitats, as mapped by Living Wales. \n",
    "\n",
    "Topics include: \n",
    "\n",
    "1. Querying data for an area and period of interest\n",
    "2. Loading data from datacube\n",
    "3. Cleaning Sentinel-2 data\n",
    "4. Mapping burnt areas\n",
    "5. Mapping changes in burn scars\n",
    "6. Estimating and reporting on burn extent \n",
    "7. Automatised reporting on burnt habitats \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jupyter Notebooks\n",
    "#### Running (executing) a cell\n",
    "Jupyter Notebooks allow code to be separated into sections that can be executed independent of one another.\n",
    "These sections are called \"cells\".\n",
    "\n",
    "Python code is written into individual cells that can be executed by placing the cursor in the cell and typing `Shift-Enter` on the keyboard or selecting the &#9658; \"Run\" button in the ribbon at the top of the notebook.\n",
    "These options will run a single cell at a time.\n",
    "\n",
    "To automatically run all cells in a notebook, navigate to the \"Cell\" tab of the menu bar at the top of JupyterLab and select \"Run All\" (or the option that best suits your needs).\n",
    "When a cell is run, the cell's content is executed.\n",
    "Any output produced from running the cell will appear directly below it.\n",
    "\n",
    "Run the cell below as a test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"I ran a cell!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cell status\n",
    "The `[ ]:` symbol to the left of each Code cell describes the state of the cell:\n",
    "\n",
    "* `[ ]:` means that the cell has not been run yet.\n",
    "* `[*]:` means that the cell is currently running.\n",
    "* `[1]:` means that the cell has finished running and was the first cell run. The number indicates the order that the cells were run in.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "To run this analysis, run all the cells in the notebook starting with the 'Load packages' and 'Connect to the datacube' cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages\n",
    "\n",
    "Load key Python packages and supporting functions for the analysis, then connect to the datacube. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "\n",
    "import sys\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "from time import time as time\n",
    "import datetime as dt\n",
    "\n",
    "import datacube\n",
    "from datacube.utils.geometry import Geometry, CRS\n",
    "from shapely.geometry.polygon import Polygon\n",
    "\n",
    "sys.path.append(\"../wales_utils/data_cube_utilities\")\n",
    "from wdc_datahandling import geom_fromextent, cleaning_s2, cloud_coverage\n",
    "from display_tools import map_extent, year_range_slider, cloud_threshold_slider, display_da\n",
    "\n",
    "sys.path.append(\"../wales_utils/themes_utilities\")\n",
    "from habitat import load_habitat_map\n",
    "from fires import burnt_site_list, get_site_extent, burn_mapping, burn_progression, report_max_burn_extent, report_burnt_habitats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the datacube\n",
    "Connect to the datacube so we can access Living Wales Analysis Ready Data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app=\"BurntAreas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query an area and period\n",
    "#### Area :  Please choose one of the five study sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell and pick a site\n",
    "site_selection = burnt_site_list()\n",
    "site_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get extent of the selected site\n",
    "site = get_site_extent(site_selection.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the extent of the selected forest site on ESRI World Imagery\n",
    "World Imagery provides very high resolution (one meter or better) satellite and aerial imagery in many parts of the world. For Wales, images are Maxar (Vivid) imagery, with a 0.50 meters resolution. \n",
    "\n",
    "However, it is static imagery and, as a consequence, for each place there is only one date available, which varies between sites. \n",
    "\n",
    "This image is only used for visualising the extent of the selected study site and is not used in the following analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display site extent\n",
    "m = map_extent(site)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Period: Please choose a range of years\n",
    "For this example, the default period of interest is '2021-01-01 to 2022-12-31'. \n",
    "\n",
    "You can change this period by using the slider. Please, in the context of this workshop and to avoid waiting, do not use more than 3 years. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run this cell and pick a date range\n",
    "years = year_range_slider()\n",
    "years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = str(years.value[0])+'-01-01'\n",
    "end_date = str(years.value[1])+'-12-31'\n",
    "\n",
    "print(\"Analysed period: \" + start_date + \" to \" + end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data from datacube "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare query for datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {'product': 'sen2_l2a_gcp',\n",
    "         'geopolygon': geom_fromextent(site),\n",
    "         'time': (start_date, end_date),\n",
    "         'output_crs': 'epsg:27700',\n",
    "         'measurements': ['nir','swir2','scl'],\n",
    "         'resolution': (-10,10)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "\n",
    "# Let's load the dataset\n",
    "dataset_in = dc.load(**query)\n",
    "\n",
    "# When using epsg other than 4326 (here: 27700), latitude and longitude are renamed y and x.\n",
    "# Let's correct that and rename x and y with explicit names\n",
    "dataset_in = dataset_in.rename({'x': 'longitude', 'y': 'latitude'})\n",
    "\n",
    "print(\"Datacube ready\")\n",
    "print(\"Took only \" + str(round(time()-start_time,2)) + \" seconds to load \"+ str(\n",
    "    (dataset_in.time.dt.year.max()-dataset_in.time.dt.year.min()+1).values\n",
    "    ) +\" years of data from datacube for the selected site (i.e., \"+ str(\n",
    "    len(dataset_in.time)) +\" images).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the second timestep of the dataset\n",
    "print(\"Plotting ...\")\n",
    "print(\"(Please wait until images appear. This may take a few seconds to minutes depending on your period of interest.)\")\n",
    "\n",
    "dataset_in.nir.isel(time=1).plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Sentinel-2 data\n",
    "\n",
    "As we can see in the above plot, optical data are affected by cloud cover.\n",
    "Filtering cloudy areas is therefore a requirement. \n",
    "\n",
    "The Living Wales project provides Analysis Ready Data (incl. within Wales Open Data Cube), which are satellite data that have been processed to a minimum set of requirements and organized into a form that allows immediate analysis with minimum additional user effort. \n",
    "\n",
    "In this regard, Living Wales has developed several python tools and libraries to minimize user efforts, including library to mask clouds and normalise data. \n",
    "\n",
    "Within the Wales Open Data Cube, Sentinel-2 data are provided with same format as on the EODataDown platform (i.e., with cloud mask in a separate layer and a scaling factor of 10,000). In the next cell, we clean the Sentinel-2 data (i.e., cloud masking and reflectance normalisation) using one of the data cube utilities developed by Living Wales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cloud masking and Reflectance normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we clean the Sentinel-2 data using one of the data cube utilities developed by Living Wales:   `cleaning_s2()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's clean the Sentinel-2 dataset (i.e., cloud masking and reflectance normalisation)\n",
    "dataset_clean = cleaning_s2(dataset_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping useless dates\n",
    "\n",
    "By default, all data are kept. \n",
    "However, as we can see in the above plot, cleaning data can lead to dates having only a few, or none, remaining pixels (i.e., cloud free pixels) for the region of interest. \n",
    "\n",
    "In the next cells, we drop the dates which contain less than a chosen coverage of cloud-free pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a maximum cloud cover \n",
    "cloud_max_threshold = cloud_threshold_slider()\n",
    "cloud_max_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the cloud coverage (%) for each date\n",
    "cloud_percentage = cloud_coverage(dataset_clean)\n",
    "\n",
    "# Dropping dates where cloud percentage greater than cloud maximum threshold\n",
    "data_2use = dataset_clean.where(cloud_percentage<=cloud_max_threshold.value, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise clean dataset after dropping useless dates\n",
    "print(\"Plotting ...\")\n",
    "print(\"(Please wait until images appear. This may take a few seconds)\")\n",
    "\n",
    "data_2use.nir.plot(col='time', col_wrap=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping burnt areas\n",
    "In this section, we will sense and visualise burnt areas for each (kept) date of the period of interest. \n",
    "For this, we are using the Living Wales python tool `burn_mapping()` which uses the Normalized Burn Ratio (`NBR`) index available in the custom `WDC` `calculate_indices` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensing burnt areas for each kept date\n",
    "# 'normalise' is set to 'False', as we already normalised the reflectance when cleaning the data\n",
    "burn = burn_mapping(data_2use, normalise=False)\n",
    "\n",
    "\n",
    "# Visualise burnt areas for each date\n",
    "print(\"\\n Plotting ...\")\n",
    "print(\"(Please wait until images appear. This may take a few seconds)\")\n",
    "\n",
    "burn.plot(col='time', col_wrap=7, add_colorbar=False, cmap=\"gist_heat\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping changes in burn scars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will map the changes in burn scars through the landscape using the Living Wales `burn_progression()` tool. This allows sensing of (1) newly burnt areas, (2) areas where vegetation is growing back and (3) areas still burnt, for each consecutive available date.\n",
    "\n",
    "\n",
    "- RED: newly burnt areas since previous satellite imagery\n",
    "- ORANGE: areas remaining burnt\n",
    "- BLUE: areas where vegetation is growing back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating burn change between each date of the studied period \n",
    "burn_changes = burn_progression(burn)\n",
    "\n",
    "\n",
    "# Visualising burn change between each date of the studied period \n",
    "print(\"Plotting ...\")\n",
    "print(\"(Please wait until images appear. This may take a few seconds)\")\n",
    "\n",
    "burn_changes.plot(col='time', col_wrap=7,cmap=\"jet\", add_colorbar=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating and reporting on burn extent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will calculate and plot the amount of burnt areas (in hectares) for each date of the period and region of interest.\n",
    "\n",
    "Then we will report on the maximum extent of burnt areas, and date of these, per year for the region of interest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the amount of burnt hectares for each date\n",
    "# pixel resolution is 10m --> 1 pixel is 100 m2 i.e, 0.01 ha\n",
    "burnt_area_ha = burn.where(burn > 0).count(['latitude','longitude'])*0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the amount of burnt hectares for each date\n",
    "# define figure size\n",
    "fig, ax = plt.subplots(figsize=(18,6))\n",
    "# add title\n",
    "fig.suptitle('Burnt area (ha)', fontsize=20)\n",
    "# plot amount of burnt areas\n",
    "ax.plot(burnt_area_ha.time.values, burnt_area_ha.values,\"o\",color=\"red\")\n",
    "# set axises properties: y axis start at 0 ; x axis dates with format year-month oriented 45degrees\n",
    "ax.set_ylim(bottom=0)\n",
    "ax.xaxis.set_major_locator(mdates.MonthLocator())\n",
    "ax.xaxis.set_major_formatter(DateFormatter(\"%Y-%m\"))\n",
    "ax.tick_params('x',labelrotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate report of the annual maximum burnt area (ha) and the date when it happened.\n",
    "report_annual_burnt_area = report_max_burn_extent(burnt_area_ha)\n",
    "\n",
    "# print report for each year\n",
    "print(\"\\nREPORTED MAXIMUM EXTENT OF BURNT AREA PER YEAR IN THE REGION OF INTEREST, WITH RESPECTIVE DATE: \\n\")\n",
    "[print(report_total_year) for report_total_year in report_annual_burnt_area][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatised reporting on burnt habitats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will detect the type of habitats which were burnt during the period of interest and report on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading habitat map\n",
    "habitat_map = load_habitat_map(start_date, geom_fromextent(site))\n",
    "\n",
    "# Visualising habitat map for the region of interest\n",
    "display_da(habitat_map.detailed/100, 'tab20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate report of burnt habitats using the burn dataset (i.e., generated in cell 18) and the habitat map \n",
    "report = report_burnt_habitats(burn, habitat_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print report\n",
    "for year in report:\n",
    "    print(\"\\n  In \"+year+\":\")\n",
    "    for habitat in list(report[year].keys()):\n",
    "        print(str(report[year][habitat])+\" ha of \"+ habitat + \" burnt.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot report results \n",
    "numb_years=len(report)\n",
    "run=1\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18,6))\n",
    "fig.suptitle('Burnt habitat area (ha)', fontsize=20)\n",
    "x = np.arange(len(report[list(report.keys())[0]]))  # the label locations\n",
    "width = 1/(numb_years+1)  # the width of the bars\n",
    "for year in range(numb_years):\n",
    "    year_key = list(report.keys())[year]\n",
    "    ax.bar(x + (width*run), report[year_key].values(), \n",
    "           width, label=year_key)\n",
    "    run=run-1\n",
    "        \n",
    "ax.set_xticks(x, report[year_key].keys())\n",
    "ax.tick_params('x',labelrotation=90,labelsize=12)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
